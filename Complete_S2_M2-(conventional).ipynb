{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "from torchvision import transforms, models\n",
    "import pretrainedmodels\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torchvision\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misimshow(inp,name,index):\n",
    "    inp = inp.transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title('misclassified as %s' %(name))\n",
    "    #plt.savefig('D:/capstone/split_patient/S2/Output/misclassified/5fold/%d.jpg'%(index))\n",
    "\n",
    "def test_imshow(inp):\n",
    "    inp = inp.transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    \n",
    "def num_of_label(loader):\n",
    "    global n\n",
    "    label_list = []\n",
    "    n=0\n",
    "    while n < len(loader):\n",
    "        if loader == trainloader.dataset:\n",
    "            set = 'Train set'\n",
    "            label_lists = np.array(train[n][1])\n",
    "            label_list = np.append(label_list,label_lists)\n",
    "            n+=1\n",
    "        elif loader == validloader.dataset:\n",
    "            set = 'Valid set'\n",
    "            label_lists = np.array(valid[n][1])\n",
    "            label_list = np.append(label_list,label_lists)\n",
    "            n+=1\n",
    "        elif loader == testloader.dataset:\n",
    "            set = 'Test set'\n",
    "            label_lists = np.array(test[n][1])\n",
    "            label_list = np.append(label_list,label_lists)\n",
    "            n+=1\n",
    "    unique, counts = np.unique(label_list, return_counts=True)\n",
    "    print('{} : {}'.format(set,dict(zip(unique, counts))))\n",
    "    \n",
    "def result_graph():\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'b',label = 'train accuracy')\n",
    "    plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'valid accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc')\n",
    "    plt.title('Acc Curve')\n",
    "    plt.legend()\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(1,len(train_losses)+1),train_losses,'b',label = 'train loss')\n",
    "    plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'valid loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=0, verbose=0):\n",
    "        self._step = 0\n",
    "        self._loss = float('inf')\n",
    "        self.patience  = patience\n",
    "        self.verbose = verbose\n",
    " \n",
    "    def validate(self, loss):\n",
    "        if self._loss < loss:\n",
    "            self._step += 1\n",
    "            if self._step > self.patience:\n",
    "                if self.verbose:\n",
    "                    print('Training process is stopped early....')\n",
    "                return True\n",
    "        else:\n",
    "            self._step = 0\n",
    "            self._loss = loss\n",
    " \n",
    "        return False\n",
    "\n",
    "def confmat(loader):\n",
    "    model.load_state_dict(torch.load('s2-s3_1fold.pt'))\n",
    "    model.eval()\n",
    "    volatile=True\n",
    "    running_correct = 0\n",
    "    nb_classes = 2\n",
    "    index = 0\n",
    "    roc_max_diff, roc_target = [],[]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for data,target in loader:\n",
    "            PIL_image = data\n",
    "            inputs,target = data.cpu(),target.cpu()\n",
    "            if loader == validloader:\n",
    "                length = len(target)\n",
    "                for v in range(length):\n",
    "                    data_orin = transform_normalize(data[v])\n",
    "                    if v == 0:\n",
    "                        data_all = data_orin.unsqueeze(0)\n",
    "                    if v != 0:\n",
    "                        data_orin = data_orin.unsqueeze(0)\n",
    "                        data_all = torch.cat((data_all,data_orin),0)\n",
    "                if is_cuda:\n",
    "                #원본에 대한 결과값 , 16개의 원본 배치에 대한 값을 outputs_original에 받음\n",
    "                    inputs_original, target = data_all.cuda() , target.cuda()\n",
    "                inputs_original , target = Variable(inputs_original),Variable(target)\n",
    "                outputs_original = model(inputs_original)\n",
    "                outputs_original = torch.sigmoid(outputs_original)\n",
    "                \n",
    "                #length = len(target)\n",
    "                #if is_cuda:\n",
    "                #    img,target = img.cuda(),target.cuda()\n",
    "\n",
    "                for i in range(length):\n",
    "                    img = PIL_image[i]\n",
    "                    img = torchvision.transforms.ToPILImage()(img)\n",
    "                    #시작점 랜덤하게 잡기(지금은 임의로 29*29점을 초기 값으로 잡음)\n",
    "                    random_init_W = 29\n",
    "                    random_init_H = 29\n",
    "                    # 랜덤 크롭 실행\n",
    "                    img_random_crop = torchvision.transforms.functional.resized_crop(img,random_init_W,random_init_H,239,239,(299,299))\n",
    "                    img_random_crop = transform(img_random_crop)\n",
    "                    img_random_crop = img_random_crop.unsqueeze(0)\n",
    "                    # V Flip\n",
    "                    img_VFlip = torchvision.transforms.functional.vflip(img)\n",
    "                    img_VFlip = transform(img_VFlip)\n",
    "                    img_VFlip = img_VFlip.unsqueeze(0)\n",
    "                    # H Flip\n",
    "                    img_HFlip = torchvision.transforms.functional.hflip(img)\n",
    "                    img_HFlip = transform(img_HFlip)\n",
    "                    img_HFlip = img_HFlip.unsqueeze(0)\n",
    "                    # rotate\n",
    "                    img_rotate = torchvision.transforms.functional.rotate(img,90)\n",
    "                    img_rotate = transform(img_rotate)\n",
    "                    # 차원 확장(배치를 쌓기위해)\n",
    "                    img_rotate = img_rotate.unsqueeze(0)\n",
    "                    concat_image = torch.cat((img_random_crop, img_VFlip, img_HFlip, img_rotate), 0)\n",
    "                    concat_image =  concat_image.cuda()\n",
    "                    concat_image = Variable(concat_image)\n",
    "                    \n",
    "                    outputs = model(concat_image)\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "                   \n",
    "                #원본 + 패치들의 값들을 더하기\n",
    "                    for j in range(4):\n",
    "                        outputs_original[i,0] += outputs[j,0]\n",
    "                        outputs_original[i,1] += outputs[j,1]\n",
    "                        \n",
    "                    outputs_original[i] = outputs_original[i]/5\n",
    "\n",
    "                _, preds = torch.max(outputs_original, 1)\n",
    "                running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() \n",
    "                \n",
    "                preds,target,inputs = preds.cpu(),target.cpu(),inputs.cpu()\n",
    "                mpreds,mtarget,minputs = preds.numpy(),target.numpy(),inputs.numpy()\n",
    "                for m in range(len(mpreds)):\n",
    "                    index = index +1\n",
    "                    o = (mpreds[m]==mtarget[m]).astype(np.float32)\n",
    "                    if o != 1:\n",
    "                        mis = mpreds[m]\n",
    "                        if mis != 0:\n",
    "                            name = 'melanoma'\n",
    "                        else:\n",
    "                            name = 'benign'        \n",
    "                        misimshow(minputs[m],name,index)\n",
    "                        \n",
    "            if loader == testloader:\n",
    "                length = len(target)\n",
    "                for v in range(length):\n",
    "                    data_orin = transform_normalize(data[v])\n",
    "                    if v == 0:\n",
    "                        data_all = data_orin.unsqueeze(0)\n",
    "                    if v != 0:\n",
    "                        data_orin = data_orin.unsqueeze(0)\n",
    "                        data_all = torch.cat((data_all,data_orin),0)\n",
    "                if is_cuda:\n",
    "                #원본에 대한 결과값 , 16개의 원본 배치에 대한 값을 outputs_original에 받음\n",
    "                    inputs_original, target = data_all.cuda() , target.cuda()\n",
    "                inputs_original , target = Variable(inputs_original),Variable(target)\n",
    "                outputs_original = model(inputs_original)\n",
    "                outputs_original = torch.sigmoid(outputs_original)\n",
    "                \n",
    "                #length = len(target)\n",
    "\n",
    "                for i in range(length):\n",
    "                    img = PIL_image[i]\n",
    "                    img = torchvision.transforms.ToPILImage()(img)\n",
    "                    #시작점 랜덤하게 잡기\n",
    "                    random_init_W = 29\n",
    "                    random_init_H = 29 #random.randint(0,58)\n",
    "                    # 랜덤 크롭 실행\n",
    "                    img_random_crop = torchvision.transforms.functional.resized_crop(img,random_init_W,random_init_H,239,239,(299,299))\n",
    "                    img_random_crop = transform(img_random_crop)\n",
    "                    img_random_crop = img_random_crop.unsqueeze(0)\n",
    "                    \n",
    "                    # V Flip\n",
    "                    img_VFlip = torchvision.transforms.functional.vflip(img)\n",
    "                    #img_VFlip = torchvision.transforms.ToTensor()(img_VFlip)\n",
    "                    img_VFlip = transform(img_VFlip)\n",
    "                    img_VFlip = img_VFlip.unsqueeze(0)\n",
    "\n",
    "                    # H Flip\n",
    "                    img_HFlip = torchvision.transforms.functional.hflip(img)\n",
    "                    #img_HFlip = torchvision.transforms.ToTensor()(img_HFlip)\n",
    "                    img_HFlip = transform(img_HFlip)\n",
    "                    img_HFlip = img_HFlip.unsqueeze(0)\n",
    "\n",
    "                    # rotate\n",
    "                    img_rotate = torchvision.transforms.functional.rotate(img,90)\n",
    "                    #img_rotate = torchvision.transforms.ToTensor()(img_rotate)\n",
    "                    img_rotate = transform(img_rotate)\n",
    "                    # 차원 확장(배치를 쌓기위해)\n",
    "                    img_rotate = img_rotate.unsqueeze(0)\n",
    "\n",
    "                    concat_image = torch.cat((img_random_crop, img_VFlip, img_HFlip, img_rotate), 0)\n",
    "                    concat_image =  concat_image.cuda()\n",
    "                    concat_image = Variable(concat_image)\n",
    "                    \n",
    "                    outputs = model(concat_image)\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "                    for j in range(4):\n",
    "                        outputs_original[i,0] += outputs[j,0]\n",
    "                        outputs_original[i,1] += outputs[j,1]\n",
    "                   #원본과 패치들의 값을 다 더한후 평균 내주기\n",
    "                    \n",
    "                    outputs_original[i] = outputs_original[i]/5\n",
    "                    \n",
    "                    #평균낸 값에서 멜라노마인 부분의 score를 쌓음\n",
    "                \n",
    "                    roc_max_diff = np.append(roc_max_diff,outputs_original[i,1])\n",
    "            \n",
    "                _, preds = torch.max(outputs_original, 1)\n",
    "                running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() \n",
    "                roc_target = np.append(roc_target,target)\n",
    "                \n",
    "            if loader == validloader:\n",
    "                for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "            if loader == testloader:   \n",
    "                for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "        accuracy = 100. * running_correct/len(loader.dataset)\n",
    "                    \n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            s[i][j] = confusion_matrix[i][j]\n",
    "    TN,FP,FN,TP = s[0][0],s[0][1],s[1][0],s[1][1]\n",
    "    PE = ((TP+FN)/(len(loader.dataset)))*((TP+FP)/(len(loader.dataset)))+((FP+TN)/(len(loader.dataset)))*((FN+TN)/(len(loader.dataset)))\n",
    "    print(confusion_matrix)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "    print('TP = {}, FP = {}, TN = {}, FN = {}'.format(TP,FP,TN,FN))\n",
    "    print('Specifity = {:.4f}, Sensitivity = {:.4f}'.format(TN/(TN+FP),TP/(TP+FN)))\n",
    "    print('F1 score = {:.4f}'.format(TP/(TP+(FN+FP)/2)))\n",
    "    if loader == testloader:\n",
    "        print('Test Acc = {:.4f}'.format(accuracy))\n",
    "        accuracy = accuracy.type(torch.FloatTensor)\n",
    "        PE = PE.type(torch.FloatTensor)\n",
    "        Kappa = (0.01*accuracy-PE)/(1.0-PE)\n",
    "        Kappa = Kappa.type(torch.FloatTensor)\n",
    "        print('cohens kappa = {:.4f}'.format(Kappa))\n",
    "        fpr, tpr, _ = roc_curve(roc_target,roc_max_diff)\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        np.save(output_path + \"fpr1.npy\", fpr)\n",
    "        np.save(output_path + \"tpr1.npy\", tpr)\n",
    "        np.save(output_path + \"auc1.npy\", roc_auc)\n",
    "        np.save(output_path + \"roc_target1.npy\", roc_target)\n",
    "        np.save(output_path + \"roc_max_diff1.npy\", roc_max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune = False\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "if not fine_tune:\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "n_features = model.fc.in_features\n",
    "model.dropout = nn.Dropout(p=0.5)\n",
    "model.fc = nn.Linear(n_features, 2)\n",
    "##for vgg\n",
    "#model.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9,nesterov=True)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='train',volatile=False):\n",
    "    if phase == 'train':\n",
    "        exp_lr_scheduler.step()\n",
    "        model.train()\n",
    "    if phase == 'valid':\n",
    "        model.eval()   \n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , (data,target) in enumerate(data_loader):\n",
    "        PIL_image = data\n",
    "        inputs,target = data.cpu(),target.cpu()\n",
    "        if phase == 'valid':\n",
    "            with torch.no_grad():\n",
    "                length = len(target)\n",
    "                for v in range(length):\n",
    "                    data_orin = transform_normalize(data[v])\n",
    "                    if v == 0:\n",
    "                        data_all = data_orin.unsqueeze(0)\n",
    "                    if v != 0:\n",
    "                        data_orin = data_orin.unsqueeze(0)\n",
    "                        data_all = torch.cat((data_all,data_orin),0)\n",
    "                if is_cuda:\n",
    "                #원본에 대한 결과값 , 16개의 원본 배치에 대한 값을 outputs_original에 받음\n",
    "                    inputs_original, target = data_all.cuda() ,target.cuda()\n",
    "                inputs_original , target = Variable(inputs_original),Variable(target)\n",
    "                outputs_original = model(inputs_original)\n",
    "                outputs_original = torch.sigmoid(outputs_original)\n",
    "                \n",
    "                #length = len(target)\n",
    "                #if is_cuda:\n",
    "                #    img,target = img.cuda(),target.cuda()\n",
    "\n",
    "                for i in range(length):\n",
    "                    img = PIL_image[i]\n",
    "                    img = torchvision.transforms.ToPILImage()(img)\n",
    "                    #시작점 랜덤하게 잡기\n",
    "                    random_init_W = 29\n",
    "                    random_init_H = 29\n",
    "                    # 랜덤 크롭 실행\n",
    "                    img_random_crop = torchvision.transforms.functional.resized_crop(img,random_init_W,random_init_H,239,239,(299,299))\n",
    "                    #img_random_crop = torchvision.transforms.ToTensor()(img_random_crop)\n",
    "                    img_random_crop = transform(img_random_crop)\n",
    "                    img_random_crop = img_random_crop.unsqueeze(0)\n",
    "                    \n",
    "                    # V Flip\n",
    "                    img_VFlip = torchvision.transforms.functional.vflip(img)\n",
    "                    #img_VFlip = torchvision.transforms.ToTensor()(img_VFlip)\n",
    "                    img_VFlip = transform(img_VFlip)\n",
    "                    img_VFlip = img_VFlip.unsqueeze(0)\n",
    "\n",
    "                    # H Flip\n",
    "                    img_HFlip = torchvision.transforms.functional.hflip(img)\n",
    "                    #img_HFlip = torchvision.transforms.ToTensor()(img_HFlip)\n",
    "                    img_HFlip = transform(img_HFlip)\n",
    "                    img_HFlip = img_HFlip.unsqueeze(0)\n",
    "\n",
    "                    # rotate\n",
    "                    img_rotate = torchvision.transforms.functional.rotate(img,90)\n",
    "                    #img_rotate = torchvision.transforms.ToTensor()(img_rotate)\n",
    "                    img_rotate = transform(img_rotate)\n",
    "                    # 차원 확장(배치를 쌓기위해)\n",
    "                    img_rotate = img_rotate.unsqueeze(0)\n",
    "\n",
    "                    concat_image = torch.cat((img_random_crop, img_VFlip, img_HFlip, img_rotate), 0)\n",
    "                    concat_image =  concat_image.cuda()\n",
    "                    concat_image = Variable(concat_image)\n",
    "\n",
    "                    outputs = model(concat_image)\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "                    \n",
    "                    #원본 + 패치들의 값들을 더하기\n",
    "                    for j in range(4):\n",
    "                        outputs_original[i,0] += outputs[j,0]\n",
    "                        outputs_original[i,1] += outputs[j,1]\n",
    "\n",
    "                    outputs_original[i] = outputs_original[i]/5\n",
    "\n",
    "                loss = criterion(outputs_original,target)  \n",
    "                running_loss += loss.data.item()\n",
    "                _, preds = torch.max(outputs_original, 1)\n",
    "                running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() \n",
    "        \n",
    "        if phase == 'train':\n",
    "            if is_cuda:\n",
    "                inputs,target = data.cuda(),target.cuda()\n",
    "            inputs , target = Variable(inputs,volatile),Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(inputs)\n",
    "            loss = criterion(output,target)  \n",
    "            running_loss += loss.data.item()\n",
    "            preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "            running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
    "    \n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, loss, accuracy))\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/399\n",
      "----------\n",
      "train Loss: 0.1899 Acc: 86.0000\n",
      "valid Loss: 0.0240 Acc: 93.0000\n",
      "\n",
      "Epoch 1/399\n",
      "----------\n",
      "train Loss: 0.1381 Acc: 89.0000\n",
      "valid Loss: 0.0259 Acc: 89.0000\n",
      "\n",
      "Epoch 2/399\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 90.0000\n",
      "valid Loss: 0.0228 Acc: 94.0000\n",
      "\n",
      "Epoch 3/399\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 90.0000\n",
      "valid Loss: 0.0221 Acc: 95.0000\n",
      "\n",
      "Epoch 4/399\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 91.0000\n",
      "valid Loss: 0.0216 Acc: 96.0000\n",
      "\n",
      "Epoch 5/399\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 91.0000\n",
      "valid Loss: 0.0228 Acc: 96.0000\n",
      "\n",
      "Epoch 6/399\n",
      "----------\n",
      "train Loss: 0.1084 Acc: 92.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 7/399\n",
      "----------\n",
      "train Loss: 0.1108 Acc: 92.0000\n",
      "valid Loss: 0.0216 Acc: 96.0000\n",
      "\n",
      "Epoch 8/399\n",
      "----------\n",
      "train Loss: 0.1173 Acc: 91.0000\n",
      "valid Loss: 0.0276 Acc: 85.0000\n",
      "\n",
      "Epoch 9/399\n",
      "----------\n",
      "train Loss: 0.0879 Acc: 92.0000\n",
      "valid Loss: 0.0240 Acc: 91.0000\n",
      "\n",
      "Epoch 10/399\n",
      "----------\n",
      "train Loss: 0.0436 Acc: 95.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 11/399\n",
      "----------\n",
      "train Loss: 0.0487 Acc: 95.0000\n",
      "valid Loss: 0.0224 Acc: 95.0000\n",
      "\n",
      "Epoch 12/399\n",
      "----------\n",
      "train Loss: 0.0435 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 96.0000\n",
      "\n",
      "Epoch 13/399\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 95.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 14/399\n",
      "----------\n",
      "train Loss: 0.0375 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 15/399\n",
      "----------\n",
      "train Loss: 0.0447 Acc: 95.0000\n",
      "valid Loss: 0.0217 Acc: 96.0000\n",
      "\n",
      "Epoch 16/399\n",
      "----------\n",
      "train Loss: 0.0343 Acc: 95.0000\n",
      "valid Loss: 0.0217 Acc: 97.0000\n",
      "\n",
      "Epoch 17/399\n",
      "----------\n",
      "train Loss: 0.0395 Acc: 94.0000\n",
      "valid Loss: 0.0214 Acc: 97.0000\n",
      "\n",
      "Epoch 18/399\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 19/399\n",
      "----------\n",
      "train Loss: 0.0373 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 20/399\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 95.0000\n",
      "valid Loss: 0.0216 Acc: 97.0000\n",
      "\n",
      "Epoch 21/399\n",
      "----------\n",
      "train Loss: 0.0293 Acc: 96.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 22/399\n",
      "----------\n",
      "train Loss: 0.0244 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 23/399\n",
      "----------\n",
      "train Loss: 0.0267 Acc: 95.0000\n",
      "valid Loss: 0.0216 Acc: 96.0000\n",
      "\n",
      "Epoch 24/399\n",
      "----------\n",
      "train Loss: 0.0314 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 25/399\n",
      "----------\n",
      "train Loss: 0.0307 Acc: 96.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 26/399\n",
      "----------\n",
      "train Loss: 0.0350 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 96.0000\n",
      "\n",
      "Epoch 27/399\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 96.0000\n",
      "\n",
      "Epoch 28/399\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 95.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 29/399\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 96.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 30/399\n",
      "----------\n",
      "train Loss: 0.0303 Acc: 95.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 31/399\n",
      "----------\n",
      "train Loss: 0.0325 Acc: 95.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 32/399\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 33/399\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 34/399\n",
      "----------\n",
      "train Loss: 0.0243 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 35/399\n",
      "----------\n",
      "train Loss: 0.0269 Acc: 96.0000\n",
      "valid Loss: 0.0216 Acc: 96.0000\n",
      "\n",
      "Epoch 36/399\n",
      "----------\n",
      "train Loss: 0.0260 Acc: 96.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 37/399\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 96.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 38/399\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 96.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 39/399\n",
      "----------\n",
      "train Loss: 0.0336 Acc: 95.0000\n",
      "valid Loss: 0.0211 Acc: 98.0000\n",
      "\n",
      "Epoch 40/399\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 95.0000\n",
      "valid Loss: 0.0217 Acc: 96.0000\n",
      "\n",
      "Epoch 41/399\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 96.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 42/399\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 96.0000\n",
      "valid Loss: 0.0214 Acc: 98.0000\n",
      "\n",
      "Epoch 43/399\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 96.0000\n",
      "valid Loss: 0.0216 Acc: 96.0000\n",
      "\n",
      "Epoch 44/399\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 45/399\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 96.0000\n",
      "valid Loss: 0.0217 Acc: 98.0000\n",
      "\n",
      "Epoch 46/399\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 47/399\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 48/399\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 96.0000\n",
      "valid Loss: 0.0216 Acc: 97.0000\n",
      "\n",
      "Epoch 49/399\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 95.0000\n",
      "valid Loss: 0.0214 Acc: 97.0000\n",
      "\n",
      "Epoch 50/399\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 95.0000\n",
      "valid Loss: 0.0216 Acc: 96.0000\n",
      "\n",
      "Epoch 51/399\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 52/399\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 96.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 53/399\n",
      "----------\n",
      "train Loss: 0.0262 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 54/399\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 95.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 55/399\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 98.0000\n",
      "\n",
      "Epoch 56/399\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 96.0000\n",
      "valid Loss: 0.0213 Acc: 98.0000\n",
      "\n",
      "Epoch 57/399\n",
      "----------\n",
      "train Loss: 0.0241 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 58/399\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "\n",
      "Epoch 59/399\n",
      "----------\n",
      "train Loss: 0.0214 Acc: 96.0000\n",
      "valid Loss: 0.0214 Acc: 97.0000\n",
      "\n",
      "Epoch 60/399\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 96.0000\n",
      "valid Loss: 0.0215 Acc: 97.0000\n",
      "Training process is stopped early....\n",
      "\n",
      "tensor([[79.,  1.],\n",
      "        [ 3., 77.]])\n",
      "tensor([0.9875, 0.9625])\n",
      "TP = 77.0, FP = 1.0, TN = 79.0, FN = 3.0\n",
      "Specifity = 0.9875, Sensitivity = 0.9625\n",
      "F1 score = 0.9747\n",
      "\n",
      "Avg valid Loss: 0.0215 Acc: 97.0000\n",
      "Training complete in 40m 16s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 400\n",
    "\n",
    "output_path = 'D:/capstone/split_patient/S2-S3/Output/ROC/'\n",
    "transform = transforms.Compose([transforms.Resize((299,299))\n",
    "                                ,transforms.ToTensor()\n",
    "                                   ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "transform_non_normalize = transforms.Compose([transforms.Resize((299,299))\n",
    "                                       ,transforms.ToTensor()])\n",
    "transform_normalize = transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train = ImageFolder('D:/capstone/split_patient/S2-S3/1fold/train',transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "#S1은 transforms로 S2는 transform으로\n",
    "valid = ImageFolder('D:/capstone/split_patient/S2-S3/1fold/valid',transform=transform_non_normalize)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False, num_workers=5, pin_memory=True)\n",
    "\n",
    "test = ImageFolder('D:/capstone/split_patient/raw data/test',transform=transform_non_normalize)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=5, pin_memory=True)\n",
    "\n",
    "\n",
    "init_state = copy.deepcopy(model.state_dict())\n",
    "init_state_opt = copy.deepcopy(optimizer.state_dict())\n",
    "init_state_lr = copy.deepcopy(exp_lr_scheduler.state_dict())\n",
    "\n",
    "since = time.time()\n",
    "avg_val_losses, avg_val_accuracy = [],[]\n",
    "early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "\n",
    "model.load_state_dict(init_state)\n",
    "optimizer.load_state_dict(init_state_opt)\n",
    "exp_lr_scheduler.load_state_dict(init_state_lr)\n",
    "\n",
    "\n",
    "    \n",
    "train_losses, train_accuracy = [],[]\n",
    "val_losses, val_accuracy = [],[]\n",
    "    \n",
    " \n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    print()\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,trainloader,phase='train')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,validloader,phase='valid')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "        \n",
    "    if early_stopping.validate(val_epoch_loss):\n",
    "        break\n",
    "avg_val_losses.append(val_epoch_loss)\n",
    "avg_val_accuracy.append(val_epoch_accuracy)\n",
    "torch.save(model.state_dict(),'s2-s3_1fold.pt')\n",
    "print()\n",
    "confmat(validloader)\n",
    "result_graph()\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print()\n",
    "avg_val_accuracy, avg_val_losses = sum(avg_val_accuracy), sum(avg_val_losses)\n",
    "avg_val_accuracy, avg_val_losses = np.average(avg_val_accuracy), np.average(avg_val_losses)\n",
    "print('Avg valid Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                avg_val_losses, avg_val_accuracy))\n",
    "\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[97.,  3.],\n",
      "        [10., 90.]])\n",
      "tensor([0.9700, 0.9000])\n",
      "TP = 90.0, FP = 3.0, TN = 97.0, FN = 10.0\n",
      "Specifity = 0.9700, Sensitivity = 0.9000\n",
      "F1 score = 0.9326\n",
      "Test Acc = 93.0000\n",
      "cohens kappa = 0.8600\n"
     ]
    }
   ],
   "source": [
    "#num_of_label(testloader)\n",
    "confmat(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
