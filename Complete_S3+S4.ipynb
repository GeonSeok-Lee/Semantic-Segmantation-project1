{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "from torchvision import transforms, models\n",
    "import pretrainedmodels\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_2d(img,patch_shape,step=[1.0,1.0],batch_first=False):\n",
    "    patch_H, patch_W = patch_shape[0], patch_shape[1]\n",
    "    if(img.size(2)<patch_H):\n",
    "        num_padded_H_Top = (patch_H - img.size(2))//2\n",
    "        num_padded_H_Bottom = patch_H - img.size(2) - num_padded_H_Top\n",
    "        padding_H = nn.ConstantPad2d((0,0,num_padded_H_Top,num_padded_H_Bottom),0)\n",
    "        img = padding_H(img)\n",
    "    if(img.size(3)<patch_W):\n",
    "        num_padded_W_Left = (patch_W - img.size(3))//2\n",
    "        num_padded_W_Right = patch_W - img.size(3) - num_padded_W_Left\n",
    "        padding_W = nn.ConstantPad2d((num_padded_W_Left,num_padded_W_Right,0,0),0)\n",
    "        img = padding_W(img)\n",
    "    step_int = [0,0]\n",
    "    step_int[0] = int(patch_H*step[0]) if(isinstance(step[0], float)) else step[0]\n",
    "    step_int[1] = int(patch_W*step[1]) if(isinstance(step[1], float)) else step[1]\n",
    "    patches_fold_H = img.unfold(2, patch_H, step_int[0])\n",
    "    if((img.size(2) - patch_H) % step_int[0] != 0):\n",
    "        patches_fold_H = torch.cat((patches_fold_H,img[:,:,-patch_H:,].permute(0,1,3,2).unsqueeze(2)),dim=2)\n",
    "    patches_fold_HW = patches_fold_H.unfold(3, patch_W, step_int[1])   \n",
    "    if((img.size(3) - patch_W) % step_int[1] != 0):\n",
    "        patches_fold_HW = torch.cat((patches_fold_HW,patches_fold_H[:,:,:,-patch_W:,:].permute(0,1,2,4,3).unsqueeze(3)),dim=3)\n",
    "    patches = patches_fold_HW.permute(2,3,0,1,4,5)\n",
    "    patches = patches.reshape(-1,img.size(0),img.size(1),patch_H,patch_W)\n",
    "    if(batch_first):\n",
    "        patches = patches.permute(1,0,2,3,4)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misimshow(inp,name,index):\n",
    "    inp = inp.transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title('misclassified as %s' %(name))\n",
    "    plt.savefig('D:/capstone/split_patient/S1/Output/misclassified/1fold/%d.jpg'%(index))\n",
    "\n",
    "def num_of_label(loader):\n",
    "    global n\n",
    "    label_list = []\n",
    "    n=0\n",
    "    while n < len(loader):\n",
    "        if loader == trainloader.dataset:\n",
    "            set = 'Train set'\n",
    "            label_lists = np.array(train[n][1])\n",
    "            label_list = np.append(label_list,label_lists)\n",
    "            n+=1\n",
    "        elif loader == validloader.dataset:\n",
    "            set = 'Valid set'\n",
    "            label_lists = np.array(valid[n][1])\n",
    "            label_list = np.append(label_list,label_lists)\n",
    "            n+=1\n",
    "        elif loader == testloader.dataset:\n",
    "            set = 'Test set'\n",
    "            label_lists = np.array(test[n][1])\n",
    "            label_list = np.append(label_list,label_lists)\n",
    "            n+=1\n",
    "    unique, counts = np.unique(label_list, return_counts=True)\n",
    "    print('{} : {}'.format(set,dict(zip(unique, counts))))\n",
    "    \n",
    "def result_graph():\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'b',label = 'train accuracy')\n",
    "    plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'valid accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc')\n",
    "    plt.title('Acc Curve')\n",
    "    plt.legend()\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(1,len(train_losses)+1),train_losses,'b',label = 'train loss')\n",
    "    plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'valid loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=0, verbose=0):\n",
    "        self._step = 0\n",
    "        self._loss = float('inf')\n",
    "        self.patience  = patience\n",
    "        self.verbose = verbose\n",
    " \n",
    "    def validate(self, loss):\n",
    "        if self._loss < loss:\n",
    "            self._step += 1\n",
    "            if self._step > self.patience:\n",
    "                if self.verbose:\n",
    "                    print('Training process is stopped early....')\n",
    "                return True\n",
    "        else:\n",
    "            self._step = 0\n",
    "            self._loss = loss\n",
    " \n",
    "        return False\n",
    "\n",
    "def confmat(loader):\n",
    "    volatile=True\n",
    "    running_correct = 0\n",
    "    nb_classes = 2\n",
    "    index = 0\n",
    "    up_sample = nn.UpsamplingBilinear2d(size=(478, 478))\n",
    "    roc_max_diff, roc_target = [],[]\n",
    "    #테스트셋의 사이즈에 따라 100,2(human_set) 또는 200,2(Test_set)로 설정\n",
    "    average_output = torch.zeros(200,2)\n",
    "    average_output = average_output.cuda()\n",
    "    all_target = []\n",
    "    \n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "   # x = 0일떄 Model 3, x = 1일때 Model 2\n",
    "    for x in range(2):\n",
    "        alpha = 0\n",
    "        if x == 0:\n",
    "            model.load_state_dict(torch.load('s3_1fold_1reapeated.pt'))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load('s4_1fold_1reapeated.pt'))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data,target in loader:\n",
    "                #x=0과 x=1의 데이터셋은 같으므로 결과 값을 한번만 저장 \n",
    "                if x == 0:\n",
    "                    all_target = np.append(all_target,target)\n",
    "                inputs,target = data.cpu(),target.cpu()\n",
    "                if loader == testloader:\n",
    "                    if is_cuda:\n",
    "                    #원본에 대한 결과값\n",
    "                        inputs_original = data.cuda()\n",
    "                    inputs_original = Variable(inputs_original)\n",
    "                    outputs_original = model(inputs_original)\n",
    "                    outputs_original = torch.sigmoid(outputs_original)\n",
    "\n",
    "                    inputs = up_sample(inputs)\n",
    "                    img = extract_patches_2d(inputs,[299,299],step=[0.6,0.6],batch_first=True)\n",
    "                    length = len(target)\n",
    "                    if is_cuda:\n",
    "                        img,target = img.cuda(),target.cuda()\n",
    "                    img , target = Variable(img),Variable(target)\n",
    "                    for i in range(length):\n",
    "                        outputs = model(img[i])\n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "\n",
    "                    #원본 + 패치들의 값들을 더하기\n",
    "                        for j in range(4):\n",
    "                            outputs_original[i,0] += outputs[j,0]\n",
    "                            outputs_original[i,1] += outputs[j,1]\n",
    "                       #원본과 패치들의 값을 다 더한후 평균 내주기     \n",
    "                        outputs_original[i] = outputs_original[i]/5\n",
    "                        #x = 0일떄 임의의 변수에 확률 값들을 저장\n",
    "                        if x == 0:\n",
    "                            average_output[alpha,0] += outputs_original[i,0]\n",
    "                            average_output[alpha,1] += outputs_original[i,1]\n",
    "                        #x = 1일때 기존에 저장한 변수에 확률 값들을 더하고 평균내줌\n",
    "                        else:\n",
    "                            average_output[alpha,0] = (average_output[alpha,0] + outputs_original[i,0])/2\n",
    "                            average_output[alpha,1] = (average_output[alpha,1] + outputs_original[i,1])/2\n",
    "                            roc_max_diff = np.append(roc_max_diff,average_output[alpha,1])   \n",
    "                        alpha += 1\n",
    "                        #평균낸 값에서 멜라노마인 부분의 score를 쌓음\n",
    "    target = torch.from_numpy(all_target)\n",
    "    target = target.type(torch.LongTensor)\n",
    "    target = target.cuda()\n",
    "    _, preds = torch.max(average_output, 1)\n",
    "    load_preds = preds.cpu()\n",
    "    load_preds = load_preds.numpy()\n",
    "    #np.savetxt(output_path + \"load_preds.csv\", load_preds)\n",
    "    \n",
    "    #preds,target,inputs = preds.cpu(),target.cpu(),inputs.cpu()\n",
    "    #mpreds,mtarget,minputs = preds.numpy(),target.numpy(),inputs.numpy()\n",
    "    #for m in range(len(mpreds)):\n",
    "     #   index = index +1\n",
    "      #  o = (mpreds[m]==mtarget[m]).astype(np.float32)\n",
    "       # if o != 1:\n",
    "        #    mis = mpreds[m]\n",
    "         #   if mis != 0: \n",
    "          #      name = 'melanoma'\n",
    "           # else: \n",
    "            #    name = 'benign'        \n",
    "            #misimshow(minputs[m],name,index)\n",
    "    running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() \n",
    "    roc_target = np.append(roc_target,target)\n",
    "            \n",
    "    if loader == testloader:   \n",
    "        for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "    accuracy = 100. * running_correct/len(loader.dataset)\n",
    "\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            s[i][j] = confusion_matrix[i][j]\n",
    "    TN,FP,FN,TP = s[0][0],s[0][1],s[1][0],s[1][1]\n",
    "    PE = ((TP+FN)/(len(loader.dataset)))*((TP+FP)/(len(loader.dataset)))+((FP+TN)/(len(loader.dataset)))*((FN+TN)/(len(loader.dataset)))\n",
    "    print(confusion_matrix)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "    print('TP = {}, FP = {}, TN = {}, FN = {}'.format(TP,FP,TN,FN))\n",
    "    print('Specifity = {:.4f}, Sensitivity = {:.4f}'.format(TN/(TN+FP),TP/(TP+FN)))\n",
    "    print('F1 score = {:.4f}'.format(TP/(TP+(FN+FP)/2)))\n",
    "    if loader == testloader:\n",
    "        print('Test Acc = {:.4f}'.format(accuracy))\n",
    "        accuracy = accuracy.type(torch.FloatTensor)\n",
    "        PE = PE.type(torch.FloatTensor)\n",
    "        Kappa = (0.01*accuracy-PE)/(1.0-PE)\n",
    "        Kappa = Kappa.type(torch.FloatTensor)\n",
    "        print('cohens kappa = {:.4f}'.format(Kappa))\n",
    "        fpr, tpr, _ = roc_curve(roc_target,roc_max_diff)\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        #np.save(output_path + \"fpr5.npy\", fpr)\n",
    "        #np.save(output_path + \"tpr5.npy\", tpr)\n",
    "        #np.save(output_path + \"auc5.npy\", roc_auc)\n",
    "        #np.save(output_path + \"roc_target5.npy\", roc_target)\n",
    "        #np.save(output_path + \"roc_max_diff5.npy\", roc_max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune = False\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "if not fine_tune:\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "n_features = model.fc.in_features\n",
    "model.dropout = nn.Dropout(p=0.5)\n",
    "model.fc = nn.Linear(n_features, 2)\n",
    "##for vgg\n",
    "#model.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9,nesterov=True)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='train',volatile=False):\n",
    "    if phase == 'train':\n",
    "        exp_lr_scheduler.step()\n",
    "        model.train()\n",
    "    if phase == 'valid':\n",
    "        model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    up_sample = nn.UpsamplingBilinear2d(size=(478, 478))\n",
    "    for batch_idx , (data,target) in enumerate(data_loader):\n",
    "        inputs,target = data.cpu(),target.cpu()\n",
    "        if phase == 'valid':\n",
    "            with torch.no_grad():\n",
    "                if is_cuda:\n",
    "            #원본에 대한 결과값\n",
    "                    inputs_original = data.cuda()\n",
    "                inputs_original = Variable(inputs_original)\n",
    "                outputs_original = model(inputs_original)\n",
    "                outputs_original = torch.sigmoid(outputs_original)\n",
    "                inputs = up_sample(inputs)\n",
    "                img = extract_patches_2d(inputs,[299,299],step=[0.6,0.6],batch_first=True)\n",
    "                length = len(target)\n",
    "                if is_cuda:\n",
    "                    img,target = img.cuda(),target.cuda()\n",
    "                img , target = Variable(img),Variable(target)\n",
    "                for i in range(length):\n",
    "                    outputs = model(img[i])\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "                    #print(outputs.size())\n",
    "                   \n",
    "                #원본 + 패치들의 값들을 더하기\n",
    "                    for j in range(4):\n",
    "                        outputs_original[i,0] += outputs[j,0]\n",
    "                        outputs_original[i,1] += outputs[j,1]\n",
    "                        \n",
    "                    outputs_original[i] = outputs_original[i]/5\n",
    "                    \n",
    "                loss = criterion(outputs_original,target)  \n",
    "                running_loss += loss.data.item()\n",
    "                _, preds = torch.max(outputs_original, 1)\n",
    "                running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() \n",
    "        \n",
    "        if phase == 'train':\n",
    "            if is_cuda:\n",
    "                inputs,target = data.cuda(),target.cuda()\n",
    "            inputs , target = Variable(inputs,volatile),Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "         \n",
    "            output = model(inputs)\n",
    "            loss = criterion(output,target)  \n",
    "            running_loss += loss.data.item()\n",
    "            preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "            running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
    "    \n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, loss, accuracy))\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "batch_size = 16\n",
    "num_epochs = 400\n",
    "\n",
    "output_path = 'D:/capstone/split_patient/S1/Output/ROC/'\n",
    "transform = transforms.Compose([transforms.Resize((299,299))\n",
    "                                       ,transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "transforms = transforms.Compose([transforms.Resize((478,478))\n",
    "                                       ,transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train = ImageFolder('D:/capstone/split_patient/S1/data/4fold/train',transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "valid = ImageFolder('D:/capstone/split_patient/S1/data/4fold/valid',transform=transforms)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "test = ImageFolder('D:/capstone/split_patient/raw data/test',transform=transforms)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "\n",
    "init_state = copy.deepcopy(model.state_dict())\n",
    "init_state_opt = copy.deepcopy(optimizer.state_dict())\n",
    "init_state_lr = copy.deepcopy(exp_lr_scheduler.state_dict())\n",
    "\n",
    "since = time.time()\n",
    "avg_val_losses, avg_val_accuracy = [],[]\n",
    "early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "\n",
    "model.load_state_dict(init_state)\n",
    "optimizer.load_state_dict(init_state_opt)\n",
    "exp_lr_scheduler.load_state_dict(init_state_lr)\n",
    "\n",
    "\n",
    "    \n",
    "train_losses, train_accuracy = [],[]\n",
    "val_losses, val_accuracy = [],[]\n",
    "    \n",
    " \n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    print()\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,trainloader,phase='train')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,validloader,phase='valid')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "        \n",
    "    if early_stopping.validate(val_epoch_loss):\n",
    "        break\n",
    "avg_val_losses.append(val_epoch_loss)\n",
    "avg_val_accuracy.append(val_epoch_accuracy)\n",
    "torch.save(model.state_dict(),'s1_4fold.pt')\n",
    "print()\n",
    "confmat(validloader)\n",
    "result_graph()\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print()\n",
    "avg_val_accuracy, avg_val_losses = sum(avg_val_accuracy), sum(avg_val_losses)\n",
    "avg_val_accuracy, avg_val_losses = np.average(avg_val_accuracy), np.average(avg_val_losses)\n",
    "print('Avg valid Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                avg_val_losses, avg_val_accuracy))\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yonsei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:225: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\yonsei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[94.,  6.],\n",
      "        [10., 90.]])\n",
      "tensor([0.9400, 0.9000])\n",
      "TP = 90.0, FP = 6.0, TN = 94.0, FN = 10.0\n",
      "Specifity = 0.9400, Sensitivity = 0.9000\n",
      "F1 score = 0.9184\n",
      "Test Acc = 92.0000\n",
      "cohens kappa = 0.8400\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 400\n",
    "\n",
    "output_path = 'D:/capstone/split_patient/S5/Output/ROC/'\n",
    "transform = transforms.Compose([transforms.Resize((299,299))\n",
    "                                       ,transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "transforms = transforms.Compose([transforms.Resize((478,478))\n",
    "                                       ,transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "#train = ImageFolder('D:/capstone/split_patient/S1/data/4fold/train',transform=transform)\n",
    "#trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "valid = ImageFolder('D:/capstone/split_patient/S1/data/4fold/valid',transform=transforms)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "test = ImageFolder('D:/capstone/split_patient/raw data/test',transform=transforms)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=5, pin_memory=True)\n",
    "#print(test.samples)\n",
    "#num_of_label(testloader)\n",
    "confmat(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
